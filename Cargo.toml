[package]
name = "hyprstream"
version = "0.1.0-alpha-7"
edition = "2021"
description = "Real-time adaptive ML inference server with dynamic sparse weight adjustments using NanoVDB"
documentation = "https://docs.rs/hyprstream"
readme = "README.md"
license = "AGPL-3.0"
license-file = "LICENSE"
exclude = [
    "**/*.pyc",
    "**/__pycache__/",
]
repository = "https://github.com/hyprstream/hyprstream.git"

[lib]
name = "hyprstream_core"
path = "src/lib.rs"
doctest = true

[[bin]]
name = "hyprstream"
path = "src/bin/main.rs"

[dependencies]
# Arrow and DataFusion dependencies removed - focused on ML inference only
bytes = "1.9.0"
safe-path = "0.1"  # Safe path traversal prevention
futures = { version = "0.3.31", features = ["alloc"] }
futures-util = "0.3.31"
pin-project-lite = "0.2"
polars = "0.45.1"
tokio = { version = "1.43.0", features = ["rt-multi-thread", "signal", "fs"] }
tokio-rustls = "0.26.1"
tonic = { version = "0.12.3", features = ["transport", "codegen", "prost", "tls"] }
rustls = "0.23.1"
rustls-pemfile = "2.1.0"
async-trait = "0.1"
tokio-util = { version = "0.7", features = ["rt"] }
sqlparser = "0.39.0"
serde = { version = "1.0", features = ["derive"] }
serde_derive = "1.0"
lazy_static = "1.4"
serde_json = "1.0"
json-threat-protection = "0.1.1"
nix = "0.27"
users = "0.11"
rlimit = "0.10"
tracing-subscriber = { version = "0.3", features = ["env-filter", "chrono"] }

# ADBC dependencies removed - focused on ML inference only

# Configuration
config = { version = "0.13", features = ["toml", "yaml", "json"] }
toml = "0.8"
serde_yaml = "0.9"
clap = { version = "4.4", features = ["derive", "env"] }
tracing = "0.1"
parking_lot = "0.12"
num_cpus = "1.16"

# OpenVDB integration
cxx = "1.0"
tracing-log = "0.2"
tracing-appender = "0.2"
bincode = "1.3.3"
tokio-stream = { version = "0.1.17", features = ["sync"] }
hex = "0.4"
chrono = { version = "0.4", features = ["serde"] }
async-stream = "0.3"
anyhow = "1.0.95"
daemonize = "0.5.0"
prost = "0.13"
# Arrow JSON removed - focused on ML inference only

# NanoVDB and ML dependencies
thiserror = "1.0"
memmap2 = "0.9"
rand = "0.8"
# PyTorch Rust bindings - replaces Candle  
tch = { version = "0.21" }

# Candle ML Framework - REMOVED: Fully migrated to Tch (PyTorch Rust bindings)
# candle-core = "0.9.1"
# candle-nn = "0.9.1"
# candle-transformers = "0.9.1"
# candle-examples = "0.9.1"
tokenizers = { version = "0.20", features = ["onig"] }
safetensors = "0.4"
regex = "1.11"
minijinja = { version = "2.12.0", features = ["builtins"] }

# Runtime Integration Dependencies
# llama-cpp-2 = "0.1.67"          # REMOVED: Replaced by Tch (PyTorch) inference
# mistralrs dependencies commented out during Candle migration
# mistralrs = { path = "../mistral.rs/mistralrs" } 
# mistralrs-core = { path = "../mistral.rs/mistralrs-core" }
hf-hub = { version = "0.4.3", features = ["tokio"] }  # HuggingFace model downloads
uuid = { version = "1.0", features = ["v4", "serde"] }
reqwest = { version = "0.11", features = ["json", "stream"] }
lru = "0.16.1"  # LRU cache for model caching
indicatif = "0.17"              # Progress bars
fastrand = "2.0"                # Fast random number generation for sampling
xdg = "2.5"                     # XDG Base Directory specification
blake3 = "1.5"                  # Fast cryptographic hashing for checksums
tempfile = "3.9"                # Temporary files for model conversion

# HTTP API dependencies
axum = { version = "0.7", features = ["macros", "tokio"] }
tower-http = { version = "0.6", features = ["trace", "cors", "timeout"] }
url = "2.5"
urlencoding = "2.1"
half = "2.6.0"
shellexpand = "3.1.1"

[features]
default = []
cuda = []

[build-dependencies]
cc = "1.0"
bindgen = "0.70"
cxx-build = "1.0"
pkg-config = "0.3"

[dev-dependencies]
criterion = "0.5.1"
tempfile = "3.9.0"
tokio-stream = "0.1.14"

[patch.crates-io]
tch = { path = "/mnt/hyprstream/tch-rs" }
torch-sys = { path = "/mnt/hyprstream/tch-rs/torch-sys" }



