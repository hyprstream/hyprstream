[package]
name = "hyprstream"
version = "0.1.0-alpha-7"
edition = "2021"
description = "Real-time adaptive ML inference server with dynamic sparse weight adjustments using NanoVDB"
documentation = "https://docs.rs/hyprstream"
readme = "README.md"
license = "Apache-2.0"
exclude = [
    "**/*.pyc",
    "**/__pycache__/",
]
repository = "https://github.com/hyprstream/hyprstream.git"

[lib]
name = "hyprstream_core"
path = "src/lib.rs"
doctest = true

[[bin]]
name = "hyprstream"
path = "src/bin/main.rs"
doc = true

[dependencies]
arrow = "53.1.0"
arrow-flight = { version = "53.1.0", features = ["cli", "flight-sql-experimental", "tls"] }
datafusion = "42.2.0"
datafusion-common = "42.2.0"
bytes = "1.9.0"
futures = { version = "0.3.31", features = ["alloc"] }
polars = "0.45.1"
tokio = { version = "1.43.0", features = ["rt-multi-thread", "signal", "fs"] }
tokio-rustls = "0.26.1"
tonic = { version = "0.12.3", features = ["transport", "codegen", "prost", "tls"] }
rustls = "0.23.1"
rustls-pemfile = "2.1.0"
async-trait = "0.1"
sqlparser = "0.39.0"
serde = { version = "1.0", features = ["derive"] }
serde_derive = "1.0"
lazy_static = "1.4"
serde_json = "1.0"
nix = "0.27"
users = "0.11"
rlimit = "0.10"
tracing-subscriber = { version = "0.3", features = ["env-filter", "chrono"] }

# ADBC dependencies
arrow-array = "53.1.0"
arrow-schema = "53.1.0"
arrow-ipc = "53.1.0"

# Configuration
config = { version = "0.13", features = ["toml", "yaml", "json"] }
toml = "0.8"
serde_yaml = "0.9"
clap = { version = "4.4", features = ["derive", "env"] }
tracing = "0.1"
parking_lot = "0.12"
num_cpus = "1.16"

# OpenVDB integration
cxx = "1.0"
tracing-log = "0.2"
tracing-appender = "0.2"
bincode = "1.3.3"
tokio-stream = "0.1.17"
hex = "0.4"
chrono = "0.4"
async-stream = "0.3"
anyhow = "1.0.95"
daemonize = "0.5.0"
prost = "0.13"
arrow-json = "53.1.0"

# NanoVDB and ML dependencies
thiserror = "1.0"
memmap2 = "0.9"
rand = "0.8"
# tch = "0.15"  # Temporarily disabled due to dependency issues

# Runtime Integration Dependencies
llama-cpp-2 = "0.1.67"          # Rust bindings for llama.cpp
candle-core = "0.6"             # Tensor operations for LoRA
candle-nn = "0.6"               # Neural network layers
hf-hub = { version = "0.4.3", features = ["tokio"] }  # HuggingFace model downloads
uuid = { version = "1.0", features = ["v4", "serde"] }
reqwest = { version = "0.11", features = ["json", "stream"] }
indicatif = "0.17"              # Progress bars
fastrand = "2.0"                # Fast random number generation for sampling
xdg = "2.5"                     # XDG Base Directory specification

# HTTP API dependencies
axum = { version = "0.7", features = ["macros", "tokio"] }
url = "2.5"
urlencoding = "2.1"

[features]
default = []
cuda = []

[build-dependencies]
cc = "1.0"
bindgen = "0.70"
cxx-build = "1.0"
pkg-config = "0.3"

[dev-dependencies]
criterion = "0.5.1"
tempfile = "3.9.0"
tokio-stream = "0.1.14"


