# Hyprstream Docker Compose Configuration
#
# Runs hyprstream services as separate containers with IPC over shared tmpfs volume.
#
# Usage:
#   docker compose --profile cpu up        # CPU inference
#   docker compose --profile cuda128 up    # NVIDIA CUDA 12.8
#   docker compose --profile cuda130 up    # NVIDIA CUDA 13.0
#   docker compose --profile rocm71 up     # AMD ROCm 7.1
#   docker compose --profile cuda up       # Alias for cuda130 (latest)
#   docker compose --profile rocm up       # Alias for rocm71
#   docker compose run client              # Run CLI client
#   docker compose --profile flight up     # Include Flight SQL
#   docker compose --profile workers up    # Include worker (requires privileged)
#
# Build locally instead of pulling:
#   docker compose build                   # Build all images
#   docker compose build model             # Build specific service
#   docker compose --profile cpu up --build  # Build and run
#
# You must select a model profile: cpu, cuda, or rocm
# Note: ENTRYPOINT is "hyprstream", so command: provides arguments

# Reusable environment configuration
x-common-env: &common-env
  HYPRSTREAM__STORAGE__MODELS_DIR: /var/lib/hyprstream/models
  HYPRSTREAM__STORAGE__LORAS_DIR: /var/lib/hyprstream/loras
  HYPRSTREAM__STORAGE__CACHE_DIR: /var/lib/hyprstream/cache
  HYPRSTREAM__STORAGE__CONFIG_DIR: /var/lib/hyprstream/config

# Reusable build configuration
x-build-cpu: &build-cpu
  context: .
  dockerfile: Dockerfile
  args:
    VARIANT: cpu

x-build-cuda128: &build-cuda128
  context: .
  dockerfile: Dockerfile
  args:
    VARIANT: cuda128

x-build-cuda130: &build-cuda130
  context: .
  dockerfile: Dockerfile
  args:
    VARIANT: cuda130

x-build-rocm71: &build-rocm71
  context: .
  dockerfile: Dockerfile
  args:
    VARIANT: rocm71

services:
  event:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "event", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream

  registry:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "registry", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - event

  policy:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "policy", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - event

  streams:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "streams", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - event

  # Model service - CPU
  model:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "model", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - registry
      - policy
    profiles:
      - cpu

  # Model service - NVIDIA CUDA 12.8
  model-cuda128:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cuda128}
    build: *build-cuda128
    command: ["service", "start", "model", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - registry
      - policy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - cuda128

  # Model service - NVIDIA CUDA 13.0
  model-cuda130:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cuda130}
    build: *build-cuda130
    command: ["service", "start", "model", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - registry
      - policy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - cuda130
      - cuda  # alias points to latest CUDA version

  # Model service - AMD ROCm
  model-rocm:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-rocm71}
    build: *build-rocm71
    command: ["service", "start", "model", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - registry
      - policy
    devices:
      - /dev/kfd
      - /dev/dri
    profiles:
      - rocm71
      - rocm  # alias for backwards compatibility

  oai:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "oai", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    ports:
      - "8010:8080"
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - policy
      # Note: Does not depend on model directly - ZMQ handles reconnection
      # This allows using any model profile (cpu/cuda/rocm)

  # CLI client - connects to services via shared IPC volume
  client:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    # No command: uses CMD [] default (runs hyprstream CLI)
    environment:
      <<: *common-env
    stdin_open: true
    tty: true
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - oai
    profiles:
      - client

  # Optional: Flight SQL service
  flight:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "flight", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    ports:
      - "50051:50051"
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
    depends_on:
      - registry
    profiles:
      - flight

  # Optional: Worker service (requires privileged for Kata VM sandboxing)
  worker:
    image: ghcr.io/hyprstream/hyprstream:${TAG:-latest-cpu}
    build: *build-cpu
    command: ["service", "start", "worker", "--foreground", "--ipc"]
    environment:
      <<: *common-env
    privileged: true
    volumes:
      - ipc:/run/hyprstream
      - data:/var/lib/hyprstream
      - /dev:/dev
    depends_on:
      - event
      - policy
    profiles:
      - workers 

volumes:
  # IPC sockets - tmpfs for fast communication
  ipc:
    driver: local
    driver_opts:
      type: tmpfs
      device: tmpfs
      o: size=100m,mode=1777

  # Persistent data storage (models, loras, cache, config)
  data:
